# 创建实时同步任务

实时同步任务实现了利用 PieCloudDB 的 Flink 动态执行器中间件与 Flink 实时流计算引擎进行对接，进而将计算结果数据写入 PieCloudDB 的虚拟数据仓库中。

实时同步适用于流处理场景，支持以下数据同步类型：

* 单表全量与 CDC（Change Data Capture）增量同步
* 整库全量与 CDC 增量同步
* 整库指定表的全量与 CDC 增量同步

## 创建表到表的实时同步任务

在数据集成的「**数据同步**」页面，用户可以根据业务需求分别设置数据关系、机器配置和运行配置以创建表到表的实时同步任务。参考步骤如下：

1. 切换到「**实时同步**」页面，点击 **新建实时同步** 即可进入创建页面。
2. 输入该实时同步任务的名称。
3. 从“类型”下拉列表中选择同步类型为“表到表”。
4. （可选）输入对该任务的描述。
5. 点击 **下一步** 以进入该实时同步任务的配置详情页面。

   <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/realtime-task-tt1.png" scope="external" />

6. 设置“数据关系”以定义数据流向。

   由于实时同步任务是用于处理实时数据的，为了避免在实时处理过程中因源端和目标端的表结构变化而导致的问题，用户需要手动配置字段之间的映射关系。

   <note type="attention">
      <p><ul><li>当前版本的实时表同步功能仅支持单个源表到单个目标表的同步，尚不支持涉及多个源表或目标表的同步。关于此类定制化需求，请联系 OpenPie 技术支持团队。</li><li>为保证数据一致性和完整性，在进行实时同步时，源表必须包含主键。主键能够唯一标识每条记录，防止因故障导致数据丢失或重复。如果进行部分字段关联而未将源表的主键与目标表的对应字段关联，系统将自动寻找与源表主键字段名相同的目标字段以进行关联和同步。如果未找到相应的目标字段，同步将失败。</li></ul></p>   
   </note>
   
   在「**数据关系**」页面，点击 **编辑** 并执行如下操作：
   1. 点击 **添加源表** 选择源数据源类型、源数据源和源表，点击 **确定** 后，系统将自动将其添加到编辑区，用于配置映射关系。

       <note type="attention">
          <p>对于源数据源，当前仅支持 MySQL、PostgreSQL 和 PieCloudDB TP。</p>   
       </note>

       用户也可以输入源表的别名，该选项同 SQL 中的 `AS` 语法，例如“table1 AS t1”，则表别名可输入 t1。

   2. 点击 **添加目标表** 选择目标数据源类型、目标数据源和目标表，点击 **确定** 后，系统将自动将其添加到编辑区，用于配置映射关系。

       <note type="attention">
          <p>对于目标数据源的类型，当前仅支持 PieCloudDB。而且目标表不支持多任务共享同步。</p>   
       </note>

       用户也可以输入目标表的别名，该选项同 SQL 中的 `AS` 语法，例如“table1 AS t1”，则表别名可输入 t1。
    
   3. 在编辑区域配置源表和目标表之间的字段关联。
        
      <note type="tip">
         <p>在配置数据关系时，如果进行的是整表实时同步，并且源表与目标表的表结构（即字段）完全一致，那么就无需手动进行字段关联。反之，如果源表和目标表的表结构不完全一致，或者只同步部分字段，那么就需要手动连接相关字段以建立关联。</p>   
      </note>    
   
      选择指定源表（或目标表）的字段从原点进行拖拽到目标表（或源表）的对应字段生成关系线，多个字段映射可以重复关联操作，直到源表和目标表及其字段之间的所有关系都配置完成。如下图所示。

      <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/relation-line1.png" scope="external" />
   
      <!--如果一个目标表字段是由源表字段经过处理得到，可以通过配置表达式的方式将指定的源表字段关联到目标表字段。步骤如下：
      1. 点击目标表字段前的编辑按钮，弹出表达式的编辑窗口。
      2. 输入自定义表达式（例如 I_price * I_quantity=o_totalprice）。
      3. 点击 **完成**，所配置的表达式会自动同步到目标表字段名称的下方。

        <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/configure-expr.png" scope="external" />

        如果需要修改表达式，点击目标表字段的编辑按钮进入表达式编辑窗口进行修改；如果需要取消源表与目标表之间的关联，点击关系线，再点击出现的 **X** 图标，如果关系线消失说明已解除关联。

       7. （可选）配置作为源表的事实表与维度表之间的 Join 关系。
   
       将 Join 关系组件（Inner Join/Left Join/Right Join）拖拽至指定事实表下方的“拖拽组件至此”区域，在弹出的关联窗口中选择关联表（维度表仅支持 Left Join），并将两张表的关联字段连线，点击 **完成** 即可。下图以 Inner Join 为例。

       <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/table-inner-join.png" scope="external" />     
   
       返回编辑区域后即可显示两张表的 Join 关系。如下图所示。

       <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/table-inner-join-relation1.png" scope="external" />

       如果需要修改关联字段，点击 Join 关系组件的编辑按钮进入关联窗口，将要关联的字段重新连线；如果需要取消事实表与维度表之间的关联，点击 Join 关系组件的 **X** 即可解除关联。-->

7. 修改机器配置。
   
   切换到「**机器配置**」页面，点击 **编辑** 以修改机器配置。如下机器配置设置完成后，点击 **保存** 以确认更改。

   机器配置项说明如下：

   * Job Manager CPU 核数：Job Manager 所能使用的 CPU 总数。默认值：1 Core。
   * Job Manager CPU 内存：Job Manager 的总进程内存大小。默认值：1024 Mi。
   * Task Manager CPU 核数：Task Manager 所能使用的 CPU 总数。默认值：1 Core。
   * Task Manager CPU 内存：Task Manager 的总进程内存大小。默认值：1024 Mi。
   * Task Manager Slot：Task Manager 的任务槽数量。默认值：16。
   
   其中，Job Manager 是实时同步作业的管理中心，负责接收用户提交的作业，并进行作业的调度和管理；Task Manager 是实际负责执行计算的 Worker，在其上执行实时同步作业的一组 Task；Task Manager Slot 是 Task Manager 中的最小资源调度单位，用于分配和托管任务的内存空间。

   <note type="attention">
      <p> 为避免资源浪费，当 Task Manager Slot 数量超过作业执行的默认并行度（parallelism.default）时，系统会自动将 Slot 数量调整为与并行度相等。也就是说，仅当并行度大于 Slot 数量时，系统会按照用户实际设定的 Slot 数量执行作业；反之，如果并行度小于 Slot 数量，系统会按照并行度执行作业。</p>   
   </note>   

8. 修改运行配置。

   “运行配置”展示数据同步任务的系统信息。对于实时同步任务，运行配置包括 flink checkpoint 触发间隔、超时时长、重启策略、作业并行度等配置项。

   切换到「**运行配置**」页面，首先点击 **修改** 以根据实际需求修改相应的配置信息，之后点击 **完成**。

   有关运行配置项的详细信息，请参见 **实时同步任务运行配置项说明**。

   点击 **X** 即可退出并返回配置页面。

9. 在实时同步任务的详情页面面，点击 **运行** 即可开始运行表到表的实时同步任务。

    <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/realtime-tt-run.png" scope="external" />

如果在点击 **运行** 后就发生配置相关报错，用户可以点击 **返回配置** 并根据报错信息修改相应的配置，之后可以重新运行该任务。
    
在任务运行期间，如果需要强制停止运行该任务，点击 **终止** 即可。如需重新运行该任务，用户可以点击 **重启作业** 或者 **重启任务**，重启任务将从上一个 Savepoint 开始执行。

<img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/realtime-restart.png" scope="external" />    

## 创建库到库的实时同步任务

在数据集成的「**数据同步**」页面，用户可以根据业务需求分别设置数据关系、机器配置和运行配置以创建库到库的实时同步任务。参考步骤如下：

1. 切换到「**实时同步**」页面，点击 **新建实时同步** 即可进入创建页面。
2. 输入该实时同步任务的名称。
3. 从“类型”下拉列表中选择同步类型为“库到库”。
4. （可选）输入对该任务的描述。
5. 点击 **下一步** 以进入该实时同步任务的配置详情页面。

   <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/realtime-dd.png" scope="external" />

6. 设置“数据关系”以定义数据流向。
   
   在「**数据关系**」页面，点击 **编辑** 并执行如下操作：
   1. 分别选择源数据源和目标数据源。
   2. 选择数据复制方式为“整库复制”或者“多表复制”。
   
       <note type="tip">
         <p>整库复制方式仅适用于源数据库和目标数据库中表名完全相同的情况。如果表名不一致，请选择多表复制方式。</p>   
       </note>

       如果选择“多表复制”，则点击 **添加表**，并根据需要选择源表和对应的目标表。在库到库的多表映射中，系统提供了同名表的自动匹配和填充功能。

       <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/multi-table-replic1.png" scope="external" />
    
   3. 点击 **保存** 以确认更改。

7. 修改机器配置。
   
   切换到「**机器配置**」页面，点击 **编辑** 以修改机器配置。如下机器配置设置完成后，点击 **保存** 以确认更改。

   机器配置项说明如下：

   * Job Manager CPU 核数：Job Manager 所能使用的 CPU 总数。默认值：1 Core。
   * Job Manager CPU 内存：Job Manager 的总进程内存大小。默认值：1024 Mi。
   * Task Manager CPU 核数：Task Manager 所能使用的 CPU 总数。默认值：1 Core。
   * Task Manager CPU 内存：Task Manager 的总进程内存大小。默认值：1024 Mi。
   * Task Manager Slot：Task Manager 的任务槽数量。默认值：16。
   
   其中，Job Manager 是实时同步作业的管理中心，负责接收用户提交的作业，并进行作业的调度和管理；Task Manager 是实际负责执行计算的 Worker，在其上执行实时同步作业的一组 Task；Task Manager Slot 是 Task Manager 中的最小资源调度单位，用于分配和托管任务的内存空间。

   <note type="attention">
      <p> 为避免资源浪费，当 Task Manager Slot 数量超过作业执行的默认并行度（parallelism.default）时，系统会自动将 Slot 数量调整为与并行度相等。也就是说，仅当并行度大于 Slot 数量时，系统会按照用户实际设定的 Slot 数量执行作业；反之，如果并行度小于 Slot 数量，系统会按照并行度执行作业。</p>   
   </note> 

8. 修改运行配置。

   “运行配置”展示数据同步任务的系统信息。对于实时同步任务，运行配置包括 flink checkpoint 触发间隔、超时时长、重启策略、作业并行度等配置项。

   切换到「**运行配置**」页面，点击 **修改** 以根据实际需求修改相应的配置信息，之后点击 **完成**。

   有关运行配置项的详细信息，请参见 **实时同步任务运行配置项说明**。

   点击 **X** 即可退出并返回配置页面。

9. 在实时同步任务的详情页面，点击 **运行** 即可开始运行库到库的实时同步任务。

    <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/run-realtime-job-dd.png" scope="external" />

如果在点击 **运行** 后就发生配置相关报错，用户可以点击 **返回配置** 并根据报错信息修改相应的配置，之后可以重新运行该任务。
    
与表到表的实时同步任务相同，在任务运行期间，如果需要强制停止运行该任务，点击 **终止** 即可。如需重新运行该任务，用户可以点击 **重启作业** 或者 **重启任务**，重启任务将从上一个 Savepoint 开始执行。

## 查看实时同步任务详情
  
对于执行成功的实时同步任务，用户在运行结果区域点击 **查看详情** 即可查看 flink 算子信息和运行日志等信息。

<img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/realtime-tt-success.png" scope="external" />

* 算子列表：算子列表页面展示运行中的 flink 作业的概览信息和算子详情。概览信息包括作业的运行时长、状态、开始时间等；算子列表以图形化方式展示了作业的逻辑执行图，可以查看作业中每个算子的名称、并行度、反压等信息。有关各个算子的更多信息展示在下方列表中。

   <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/operator-list.png" scope="external" />

* 异常：异常页面展示 flink 作业执行与重试过程中发生的所有异常堆栈，以协助排查问题。

   <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/abnormal.png" scope="external" />

* Checkpoints：Checkpoints 页面展示 flink 作业执行过程中所有的 checkpoint 详情、统计信息和配置信息。

   <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/checkpoints.png" scope="external" />

* Job 配置：Job 配置页面展示 flink 作业的执行配置。

   <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/job-configuration.png" scope="external" />

* 集群配置：集群配置页面展示 flink 作业所属集群的配置详情、JVM 启动参数和 classpath。

  <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/cluster-configuration.png" scope="external" />

* 运行日志：运行日志页面展示 flink 作业所属集群的 Job manager 和 Task manager 的运行日志。

  <img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/operation-log.png" scope="external" />

## 实时同步任务运行配置项说明

| 配置项           | 说明               | 默认值                    |
| --------------- | ------------------ | ------------------------- |
| execution.checkpointing.interval    | 触发检查点（Checkpoint）的时间间隔。它指定了在连续两个检查点之间应有的最小时间（毫秒）。如果设置为大于 0 的值，系统将在这个时间间隔后自动触发检查点。 | 1000  |
| execution.checkpointing.min-pause   | 这是在连续两个检查点之间的最小暂停时间（以毫秒为单位）。如果任务处理速度落后于数据生成速度，系统会暂停发送数据以等待任务赶上。该参数定义了暂停操作的最小时长。 | 500   |
| execution.checkpointing.timeout     | 检查点操作的超时时间（以毫秒为单位）。如果在指定的超时时间内检查点未能完成，系统将取消当前检查点，并尝试执行下一次检查点。 | 600000   |
| parallelism.default  | 作业执行的默认并行度。它决定了作业中所有算子的默认并行实例数。 | 1   |
| state.checkpoints.num-retained  | 保留的检查点（Checkpoint）数量。当启用了基于时间的触发检查点时，这个参数决定了在磁盘上保留多少个最近的检查点。 | 1      |
| restart-strategy.type    | 作业失败时的重启策略类型。可能的值包括：<ul><li> none：无重启策略。 </li><li>fixed-delay：固定延迟启动策略。  </li><li>failure-rate：故障率重启策略。</li></ul>  | none    |
| restart-strategy.fixed-delay.delay   | 当重启策略类型为 fixed-delay 时，该参数设置了两次连续重启尝试之间的延迟。单位：秒（s）。 | 1    |
| restart-strategy.fixed-delay.attempts | 当重启策略类型为 fixed-delay 时，该参数设置了将作业声明为失败之前重试执行的次数。-1 表示次数无上限。 | -1    |
| restart-strategy.failure-rate.delay  | 当重启策略类型为 failure-rate 时，该参数设置了两次连续重启尝试之间的延迟。单位：秒（s）。 | 1       |
| restart-strategy.failure-rate.failure-rate-interval    | 当重启策略类型为 failure-rate 时，该参数设置了测量重新启动策略故障率的时间间隔。单位：秒（s）。 | 60   |
| restart-strategy.failure-rate.max-failures-per-interval | 当重启策略类型为 failure-rate 时，该参数设置了在 failure-rate.delay 指定的时间窗口内允许的作业失败之前的最大重启次数。 | 1     |
| state.backend.dir   | 状态后端存储的目录路径用于保存实时同步作业的状态信息，包括检查点和保存点。 | 默认使用 flink 集群默认配置 |

## 实时同步常见报错与解决方案

在执行同步任务过程中，可能遇到的执行失败的情况，在任务详情页面的运行结果区域，用户可以通过查看任务的状态和执行详情来了解失败的原因。

如果任务失败是由于配置问题引起的，那么需要重新修改任务配置。用户可以点击 **返回配置** 并根据报错信息修改相应的配置，之后可以重新运行该任务。如果实时同步任务执行失败，用户可以在运行结果区域点击 **查看详情** 来查看 flink 算子信息和运行日志等信息，以辅助排查问题。

<img src="https://pdb-doc.oss-cn-beijing.aliyuncs.com/dataflow/v2/realtime-tt-fail.png" scope="external" /> 

在执行同步任务时，如果发生如下报错，可以参考相应的解决方案。

* **报错信息**：`java. lang. IllegalArgumentException: source table [database_name.table_name] do not contain any primary key`。

  **原因**：源数据表未包含主键。

  **解决方案**：为源数据表指定一个主键。同时，如果源数据库中实际的表没有主键，而用户仅在关联表模型的字段管理中修改“主键”的信息，实时同步任务在校验时同样会报错。

* **报错信息**：`java.lang.IllegalArgumentException: source[database_name.table_name] wal level is replica, should be set to logical`。

  **原因**：日志级别未设置为“replica”。

  **解决方案**：对于源数据库（通常是 PostgreSQL 系列），将其日志级别应设置为“replica”。为了启用逻辑复制（logical replication）功能，这是实时同步功能的底层依赖，需要将数据库的日志级别设置为 `wal_level=logical`。对于 PostgreSQL 系列数据库，可以通过修改配置文件并重启数据库实例来实现这一设置；而对于 PieCloudDB TP 数据库，除了直接修改配置文件外，还可以通过在计算空间平台上设置实例的 GUC 模板来进行配置。

*  **报错信息**：`java.lang.IllegalArgumentException: table [table_name] replication identity is [d], should be set to full`。
   
   **原因**：源表的 `REPLICA IDENTITY` 属性未设置为 `FULL`。  
   
   **解决方案**：修改源表的 `REPLICA IDENTITY` 属性为 `FULL`，参考 SQL 命令如下：

   ```sql
   ALTER TABLE table_name REPLICA IDENTITY FULL;
   ```

   在 PostgreSQL 中，`REPLICA IDENTITY` 属性用于确定在逻辑复制过程中，如何识别被更新或删除的行。这个属性对于确保变更数据流（Change Data Capture，CDC）的准确性至关重要。为了在实时同步中准确地识别更新（UPDATE）和删除（DELETE）操作的前后状态，需要将 `REPLICA IDENTITY` 设置为 `FULL`。这样，PostgreSQL 会在 WAL（Write-Ahead Logging）中记录足够的信息来支持逻辑复制。

